# ğŸ¤– AutoMLOps Copilot

**DigitalOcean AI Hackathon 2026 Project**

Transform any GitHub ML repository into production-ready containerized APIs automatically using AI-powered code generation.

---

## ğŸŒŸ Live Demo

**ğŸŒ Production URL:** http://129.212.144.219

**Try it now:** Paste any ML GitHub repo and watch AI generate production artifacts in real-time!

---

## ğŸ¯ Project Vision

AutoMLOps Copilot revolutionizes MLOps by automatically analyzing machine learning repositories and generating complete production infrastructure:

âœ¨ **Paste GitHub URL** â†’ **AI Analysis** â†’ **Production-Ready API**

No manual configuration. No boilerplate. Just intelligent automation.

---

## ğŸ—ï¸ System Architecture

<img width="2816" height="1536" alt="Gemini_Generated_Image_9wwzk69wwzk69wwz" src="https://github.com/user-attachments/assets/f44e24d3-3e2d-4546-800c-ff2dcc8c3f98" />

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           USER INTERFACE                                â”‚
â”‚                    React + Vite (Port 80)                               â”‚
â”‚              http://129.212.144.219                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      NGINX REVERSE PROXY                                â”‚
â”‚                      (LoadBalancer)                                     â”‚
â”‚    Routes:  /      â†’ Frontend                                           â”‚
â”‚            /api/*  â†’ Orchestrator                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â–¼                        â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚     ORCHESTRATOR      â”‚   â”‚      FRONTEND        â”‚
    â”‚    Go + Gin (x2)      â”‚   â”‚   React + Vite (x2)  â”‚
    â”‚    Port 8080          â”‚   â”‚                      â”‚
    â”‚  - Job Management     â”‚   â”‚  - Job Creation      â”‚
    â”‚  - Status Updates     â”‚   â”‚  - Real-time Updates â”‚
    â”‚  - API Endpoints      â”‚   â”‚  - Artifact Download â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚       â”‚
           â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PostgreSQL  â”‚    â”‚   Redis      â”‚
    â”‚  (Jobs DB)  â”‚    â”‚ (Job Queue)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â”‚ LPOP jobs
                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   WORKER (x2)      â”‚
                    â”‚   Python + AI      â”‚
                    â”‚                    â”‚
                    â”‚  1. Clone Repo     â”‚
                    â”‚  2. Analyze Code   â”‚
                    â”‚  3. AI Generation  â”‚
                    â”‚  4. Upload to S3   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    â”‚
                    â–¼                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Groq/Gemini  â”‚   â”‚  DO Spaces (S3)  â”‚
            â”‚   LLM APIs    â”‚   â”‚ automlops-models â”‚
            â”‚               â”‚   â”‚                  â”‚
            â”‚ - Code Gen    â”‚   â”‚ Generated Files: â”‚
            â”‚ - Analysis    â”‚   â”‚ - Dockerfile     â”‚
            â”‚               â”‚   â”‚ - app.py         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚ - training.py    â”‚
                                â”‚ - requirements   â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                    All deployed on:
            DigitalOcean Kubernetes (DOKS)
                    nyc3 region
```

---

## ğŸ“¦ Tech Stack

### **Frontend Layer**
- **Framework:** React 18 + Vite 5
- **Styling:** Tailwind CSS
- **State:** React Hooks
- **Deployment:** Nginx container (2 replicas)

### **Backend Layer**
- **API Orchestrator:** Go 1.21 + Gin Framework (2 replicas)
- **Worker Service:** Python 3.10 + Loguru (2 replicas)
- **Queue:** Redis 7.0
- **Database:** PostgreSQL 15 + GORM

### **AI/ML Layer**
- **LLM Provider:** Groq (llama-3.3-70b-versatile)
- **Fallback:** Google Gemini 1.5 Pro
- **Frameworks Detected:** TensorFlow, PyTorch, Scikit-learn, Keras, XGBoost

### **Infrastructure**
- **Container Registry:** DigitalOcean Container Registry
- **Orchestration:** Kubernetes (DOKS - 3 nodes)
- **Storage:** DigitalOcean Spaces (S3-compatible)
- **Load Balancer:** DigitalOcean LoadBalancer + Nginx
- **Region:** NYC3

### **DevOps**
- **Containerization:** Docker + Multi-stage builds
- **CI/CD:** GitHub Actions (TODO)
- **Monitoring:** Prometheus + Grafana (TODO)

---

## ğŸš€ Current Status

### âœ… **PRODUCTION READY - Phase 1 Complete**

| Component | Status | Details |
|-----------|--------|---------|
| ğŸ¨ Frontend UI | âœ… **Live** | React SPA with real-time updates |
| ğŸ”Œ API Orchestrator | âœ… **Live** | 2 replicas, REST API |
| ğŸ¤– AI Worker | âœ… **Live** | 2 replicas, LLM-powered |
| ğŸ“Š PostgreSQL | âœ… **Live** | Persistent job storage |
| ğŸ”„ Redis Queue | âœ… **Live** | Async job processing |
| ğŸŒ LoadBalancer | âœ… **Live** | Public IP: 129.212.144.219 |
| ğŸª£ DO Spaces | âœ… **Live** | S3-compatible storage |
| ğŸ³ Container Registry | âœ… **Live** | 3 images published |
| â˜¸ï¸ Kubernetes | âœ… **Live** | DOKS cluster (3 nodes) |
| ğŸ“¥ Artifact Download | âœ… **Working** | Direct from Spaces |
| ğŸ§  Code Generation | âœ… **Working** | Dockerfile, FastAPI, Training |

### ğŸš§ **Phase 2 - Coming Soon**

| Feature | Status | Priority |
|---------|--------|----------|
| ğŸ”„ CI/CD Pipelines | ğŸ“‹ Planned | High |
| ğŸ‹ï¸ GPU Training | ğŸ“‹ Planned | Medium |
| ğŸš€ Auto-Deploy APIs | ğŸ“‹ Planned | High |
| ğŸ“ˆ Monitoring | ğŸ“‹ Planned | Medium |
| ğŸ§ª Testing Suite | ğŸ“‹ Planned | Low |

---

## ğŸ“‚ Project Structure

```
automlops-copilot/
â”œâ”€â”€ frontend/                    # React + Vite UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ lib/                # API client
â”‚   â”‚   â””â”€â”€ App.tsx             # Main app
â”‚   â”œâ”€â”€ Dockerfile              # Production build
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ orchestrator/               # Go API Service
â”‚   â”œâ”€â”€ cmd/server/            # Main entry point
â”‚   â”œâ”€â”€ internal/
â”‚   â”‚   â”œâ”€â”€ handlers/          # HTTP handlers (Job CRUD)
â”‚   â”‚   â”œâ”€â”€ models/            # Data models (Job, Status)
â”‚   â”‚   â”œâ”€â”€ database/          # PostgreSQL + migrations
â”‚   â”‚   â””â”€â”€ queue/             # Redis queue client
â”‚   â”œâ”€â”€ Dockerfile             # Multi-stage build
â”‚   â””â”€â”€ go.mod
â”‚
â”œâ”€â”€ worker/                     # Python AI Agent
â”‚   â”œâ”€â”€ agent/
â”‚   â”‚   â””â”€â”€ src/
â”‚   â”‚       â”œâ”€â”€ analyzer/      # Repo analysis
â”‚   â”‚       â”‚   â””â”€â”€ repo_analyzer.py
â”‚   â”‚       â”œâ”€â”€ llm/           # LLM clients
â”‚   â”‚       â”‚   â”œâ”€â”€ groq_client.py
â”‚   â”‚       â”‚   â””â”€â”€ gemini_client.py
â”‚   â”‚       â””â”€â”€ generators/    # Code generators
â”‚   â”‚           â”œâ”€â”€ dockerfile_generator.py
â”‚   â”‚           â”œâ”€â”€ training_generator.py
â”‚   â”‚           â””â”€â”€ fastapi_generator.py
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ storage/           # S3/Spaces integration
â”‚   â”‚   â””â”€â”€ worker.py          # Main worker loop
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ k8s-manifests/             # Kubernetes Deployments
â”‚   â”œâ”€â”€ namespace.yaml
â”‚   â”œâ”€â”€ secrets.yaml
â”‚   â”œâ”€â”€ postgres.yaml
â”‚   â”œâ”€â”€ redis.yaml
â”‚   â”œâ”€â”€ orchestrator.yaml
â”‚   â”œâ”€â”€ worker.yaml
â”‚   â”œâ”€â”€ frontend.yaml
â”‚   â””â”€â”€ nginx-proxy.yaml
â”‚
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Local Development Setup

### **Prerequisites**
- Docker Desktop
- kubectl
- doctl (DigitalOcean CLI)
- Python 3.10+
- Go 1.21+
- Node.js 18+

### **1. Clone Repository**
```bash
git clone https://github.com/AyaanShaheer/automlops-copilot.git
cd automlops-copilot
```

### **2. Setup Environment Variables**

**Worker (.env):**
```bash
cd worker
cat > .env << EOF
GROQ_API_KEY=your_groq_key_here
GEMINI_API_KEY=your_gemini_key_here
LLM_PROVIDER=groq
REDIS_HOST=localhost
REDIS_PORT=6379
ORCHESTRATOR_URL=http://localhost:8080
ENABLE_S3_UPLOAD=false
TEMP_REPO_DIR=/tmp/repos
EOF
```

**Orchestrator (.env):**
```bash
cd orchestrator
cat > .env << EOF
SERVER_PORT=8080
DB_HOST=localhost
DB_PORT=5432
DB_USER=postgres
DB_PASSWORD=postgres
DB_NAME=automlops
REDIS_HOST=localhost
REDIS_PORT=6379
EOF
```

### **3. Start Local Services**
```bash
# Start PostgreSQL and Redis
docker-compose up -d postgres redis

# Start Orchestrator
cd orchestrator
go run cmd/server/main.go

# Start Worker (in new terminal)
cd worker
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
pip install -r requirements.txt
python main.py

# Start Frontend (in new terminal)
cd frontend
npm install
npm run dev
```

### **4. Access Locally**
- Frontend: http://localhost:5173
- API: http://localhost:8080
- Health: http://localhost:8080/health

---

## â˜¸ï¸ Production Deployment (DigitalOcean)

### **Prerequisites**
1. DigitalOcean account
2. DOKS cluster created
3. Container registry set up
4. Spaces bucket created

### **Step 1: Build and Push Images**
```bash
# Login to DO Registry
doctl registry login

# Build images
docker build -t registry.digitalocean.com/automlops/frontend:latest ./frontend
docker build -t registry.digitalocean.com/automlops/orchestrator:latest ./orchestrator
docker build -t registry.digitalocean.com/automlops/worker:latest ./worker

# Push to registry
docker push registry.digitalocean.com/automlops/frontend:latest
docker push registry.digitalocean.com/automlops/orchestrator:latest
docker push registry.digitalocean.com/automlops/worker:latest
```

### **Step 2: Configure Kubernetes**
```bash
# Get cluster credentials
doctl kubernetes cluster kubeconfig save your-cluster-name

# Create namespace
kubectl create namespace automlops

# Create secrets
kubectl create secret docker-registry do-registry-secret \
  --docker-server=registry.digitalocean.com \
  --docker-username=your-do-token \
  --docker-password=your-do-token \
  -n automlops

kubectl create secret generic llm-credentials \
  --from-literal=groq-api-key='your-groq-key' \
  --from-literal=gemini-api-key='your-gemini-key' \
  -n automlops

kubectl create secret generic spaces-credentials \
  --from-literal=access-key='your-spaces-key' \
  --from-literal=secret-key='your-spaces-secret' \
  -n automlops
```

### **Step 3: Deploy Services**
```bash
# Deploy all services
kubectl apply -f k8s-manifests/

# Check status
kubectl get pods -n automlops
kubectl get svc -n automlops

# Get LoadBalancer IP
kubectl get svc nginx-proxy -n automlops
```

---

## ğŸ® Usage Guide

### **1. Create a Job**
1. Visit http://129.212.144.219
2. Paste GitHub ML repo URL (e.g., `https://github.com/username/ml-project`)
3. Click "Create Job"

### **2. Monitor Progress**
Watch real-time status updates:
- â³ **Queued** - Job in queue
- ğŸ” **Analyzing** - Cloning and analyzing repo
- ğŸ—ï¸ **Building** - Generating artifacts
- â˜ï¸ **Uploading** - Uploading to Spaces
- âœ… **Completed** - Ready to download

### **3. Download Artifacts**
Click on the completed job to view and download:
- `Dockerfile` - Production-ready containerization
- `app.py` - FastAPI inference service
- `training_wrapper.py` - Model training script
- `requirements.txt` - Python dependencies
- `analysis.json` - Repository metadata

---

## ğŸ“Š Example Repositories to Test

| Repository | Framework | Description |
|------------|-----------|-------------|
| [Machine Downtime Predictor](https://github.com/AyaanShaheer/Machine_Downtime_Predictor_API) | Scikit-learn | Production example |
| [Personalized Wellness AI](https://github.com/AyaanShaheer/Personalized-Wellness-AI-) | Mixed | Complex notebook |
| Your own ML repos! | Any | Test your projects |

---

## ğŸ”‘ API Reference

### **Base URL**
```
Production: http://129.212.144.219/api
Local: http://localhost:8080/api
```

### **Endpoints**

**Create Job**
```bash
POST /api/jobs
Content-Type: application/json

{
  "repo_url": "https://github.com/username/ml-repo"
}

Response: 201 Created
{
  "job": {
    "id": "uuid",
    "repo_url": "...",
    "status": "queued",
    "created_at": "2026-02-11T..."
  }
}
```

**List Jobs**
```bash
GET /api/jobs

Response: 200 OK
[
  {
    "id": "uuid",
    "repo_url": "...",
    "status": "completed",
    "frameworks": "sklearn",
    "python_files": 1,
    "notebooks": 0
  }
]
```

**Get Job Details**
```bash
GET /api/jobs/:id

Response: 200 OK
{
  "id": "uuid",
  "status": "completed",
  "dockerfile_url": "https://...",
  "artifacts": [...]
}
```

**Health Check**
```bash
GET /health

Response: 200 OK
{
  "service": "automlops-orchestrator",
  "status": "healthy"
}
```

---

## ğŸ› Troubleshooting

### **Jobs Stuck in Queue**
```bash
# Check worker pods
kubectl get pods -n automlops -l app=worker

# View worker logs
kubectl logs -n automlops -l app=worker --tail=100
```

### **Database Connection Issues**
```bash
# Check PostgreSQL
kubectl exec -n automlops deployment/orchestrator -- env | grep DB_

# Test connection
kubectl exec -it deployment/postgres-deployment -n automlops -- psql -U postgres
```

### **Artifact Download Fails**
```bash
# Verify Spaces bucket
aws s3 ls s3://automlops-models/jobs/ --endpoint-url=https://nyc3.digitaloceanspaces.com

# Check bucket permissions (should be public-read)
```

### **LLM API Errors**
```bash
# Check API keys
kubectl get secret llm-credentials -n automlops -o yaml

# View worker logs for API errors
kubectl logs -n automlops -l app=worker --tail=50
```

---

## ğŸ¯ Roadmap

### **Phase 1: Core Platform** 
- [âœ…] Job creation and management
- [âœ…] Repository analysis using AI
- [âœ…] Artifact generation (Dockerfile, FastAPI, Training)
- [âœ…] S3/Spaces integration
- [âœ…] Kubernetes deployment
- [âœ…] Public LoadBalancer
- [âœ…] Real-time status updates

### **Phase 2: CI/CD & Automation** ğŸš§ IN PROGRESS
- [ ] Generate GitHub Actions workflows
- [ ] Generate GitLab CI configs
- [ ] Generate Jenkinsfiles
- [ ] Platform CI/CD pipeline
- [ ] Automated testing

### **Phase 3: Advanced Features** ğŸ“‹ PLANNED
- [ ] Gradient GPU training integration
- [ ] Auto-deploy generated APIs to Kubernetes
- [ ] Model versioning and tracking
- [ ] A/B testing support
- [ ] Cost estimation

### **Phase 4: Production Hardening** ğŸ”® FUTURE
- [ ] Prometheus + Grafana monitoring
- [ ] Distributed tracing (Jaeger)
- [ ] Rate limiting and quotas
- [ ] Multi-tenancy support
- [ ] Custom LLM fine-tuning

---

## ğŸ‘¥ Team

| Name | Role | Responsibilities |
|------|------|------------------|
| **Ayaan Shaheer** | Lead DevOps & AI Systems Engineer | Kubernetes, Docker, Go orchestrator, infrastructure |
| **Saif** | Frontend Engineer | React UI, user experience, real-time updates |
| **Zain** | AI/ML Engineer | Python worker, LLM integration, code generation |
| **Afzaal** | Project Coordinator | Project Management, Documentation, Presentation |

---

## ğŸ† Why This Project Stands Out
1. **ğŸ¯ Real Production Use Case** - Solves actual MLOps pain points
2. **ğŸ¤– AI-Powered** - Not just templates, intelligent code generation
3. **â˜ï¸ Full Cloud Stack** - DOKS, Spaces, Container Registry, LoadBalancer
4. **ğŸ“ˆ Scalable Architecture** - Kubernetes with horizontal scaling
5. **ğŸš€ Live Demo** - Fully functional public deployment
6. **ğŸ’¡ Innovation** - Unique approach to MLOps automation
7. **ğŸ—ï¸ Enterprise-Grade** - Production-ready infrastructure patterns

---

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details.

---

## ğŸ¤ Contributing

We welcome contributions! Please:
1. Fork the repository
2. Create a feature branch
3. Submit a pull request

For major changes, please open an issue first to discuss.

---

## ğŸ“§ Contact & Support

- **Issues:** [GitHub Issues](https://github.com/AyaanShaheer/automlops-copilot/issues)
- **Email:** [EMAIL_ADDRESS](gfever252@gmail.com)
- **Demo:** [Live Demo](http://129.212.144.219)

---

## ğŸ™ Acknowledgments

- **DigitalOcean** - For the Gradient AI Hackathon and cloud infrastructure
- **Groq** - For lightning-fast LLM inference
- **Google** - For Gemini AI capabilities
- **Open Source Community** - For amazing tools and frameworks

---

**Built with â¤ï¸ for the DigitalOcean AI Hackathon 2026**

**â­ Star this repo if you find it useful!**



